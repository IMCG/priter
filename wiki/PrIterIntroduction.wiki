#summary a brief introduction of PrIter.

= Introduction =

Iterative computations are common in myriad of data mining algorithms. The massive amount of data involved in these computations exacerbates the need for a computing cloud and a distributed framework that supports fast iterative computation. MapReduce, which powered cloud computing, is such a framework that supports data processing of massive scale. Further, a series of frameworks have been proposed for iterative computation. In particular, all of the previously proposed frameworks assume that the iterative update is equally important for all data.

However, in reality, selectively processing some portions of the data first has the potential of accelerating the iterative process, rather than simply performing a series of iterations over all the data. Some of the data points play an important decisive role in determining the final converged outcome. By giving an execution priority to some of the data, the iterative process can potentially converge fast. For example, the well-known shortest path algorithm, Dijkstra's algorithm, greedily expands the node with the shortest distance first. This will not only derive the shortest distance for all nodes fast but also be able to quickly return the nearest nodes. Unfortunately, neither MapReduce nor any existing distributed computing framework provides the support of prioritized execution.

PrIter is such a distributed framework that supports the prioritized execution of iterative computations. To realize prioritized execution, PrIter allows users to explicitly specify the priority value of each processing data point. 

= Design and Implementation =

First, we describe the requirements of a framework that supports prioritized iterative computations:

 *  The framework needs to support iterative processing. Iterative algorithms perform the same computation in each iteration, and the state from the previous iteration has to be passed to the next iteration efficiently.
 * The framework needs to support state maintenance across iterations. In MapReduce, only the previous iteration's result is needed for the next iteration's computation, while in PrIter the intermediate iteration state should be maintained across iterations due to the selective update operations.
 * The framework needs to support prioritized execution. That is, an efficient selection of the high priority data should be provided.

== Iterative Processing ==

PrIter incorporates the support of [http://code.google.com/p/i-mapreduce/ iMapReduce] for iterative processing. iMapReduce following MapReduce paradigm directly passes the reduce output to the map for the next iteration, rather than writing output to distributed file system (DFS). 

<img src="http://rio.ecs.umass.edu/~yzhang/pic/iterprocess.png" width=500/>

The data is evenly distributed among workers by a hash function, which will be used to look up the destination worker when passing messages between keys/workers. The paired map and reduce tasks always operate on the same subset of keys/nodes. We refer to the paired map/reduce task as _*MRPair*_. These tasks are persistent tasks that keep alive during the entire iterative process and maintain the intermediate iteration state. In summary, each MRPair performs the iterative computation on a data partition, and the necessary information exchange between MRPairs occurs during the maps-to-reduces shuffling.

== State Maintenance ==

Each MRPair is assigned with a subset of keys/nodes, whose values/states are maintained locally (Note that one or more fine-grained MRPairs could be assigned to a worker for load balancing. During the iterative process, a key/node's value/state is updated after an iteration. That is, the value/state for each key/node should be maintained across iterations. To ensure fast access to the value/state, we design a _*StateTable*_ at the reduce side that is implemented with an in-memory hash table.

In the context of incremental update (opposed to concurrent update in normal iteration), two types of state should be maintained. The first is the iterative state or _iState_, which is used for the iterative computation. The second is the cumulative state or _cState_ indicating a node's state, which is accumulated from all the previous iterations. 

In MapReduce, the output <key, value> pairs of various maps are sorted according to the natural order of keys, then the reduce function is performed on the grouped <key, values list> pair. However, since the StateTable supports random access, it is not necessary to perform sort between the map and reduce in PrIter, so that we eliminate the sort phase, which can significantly improve performance. Moreover, we start the reduce operation immediately upon receiving a map's output. In other words, the ``reduce'' function is applied on <key, value> rather than <key, values list>. It updates the corresponding entry in the StateTable according to a received value, rather than performs a reduce function on all the received values associated with the same key. We replace the reduce function by a _*UpdateState*_ function, which updates the iState and the cState in the StateTable.

In summary, the StateTable stores the state information of each node. The state is updated every iteration by an UpdateState function, which takes map's output <key, value> pairs as input. Users can specify the update rules to achieve their goals.

== Prioritized Execution ==

In order to perform prioritized execution, PrIter labels each node with a priority value that is specified by users. The priority information of each node is also maintained in the StateTable. During the update of node state, instead of a pass over the entire StateTable as an iteration, a pass through a selected subset as a subpass is performed based on the entries' priority values. A number of nodes with larger priority values are selected for the map operation in the next subpass. Since each MRPair holds only a subset of nodes, the priority value is compared among the nodes residing in the same MRPair instead of a global comparison across workers.

<img src="http://rio.ecs.umass.edu/~yzhang/pic/worker.png" width=500/>

Figure \ref{fig:worker} shows the data flow in a MRPair. The StateTable is updated in each subpass based on the output of the UpdateState function. The priority value is determined by another function \emph{DecidePriority}, which is for users to specify each node's execution priority taking account of the state information. For example, in SSSP, the priority value is the negative value of the cState (\emph{i.e.}, the shortest distance), while in PageRank, the priority value is exactly the same value as the iState (\emph{i.e.}, $\Delta R$). Upon the receipt of all maps' output, a priority queue containing the $\langle$node, iState$\rangle$ pairs with higher priority values is extracted from the StateTable for feeding the paired map in the next subpass. After a node is decided to be enqueued, its iState and its node id are made a copy in the priority queue, and accordingly its iState in the StateTable is reset.

The size of the priority queue shows the trade-off between the gain from the prioritized execution and the cost from the queue extraction. Setting it too long may degrade the effect of prioritization. In the extreme case that the queue size is the same size as the StateTable, there is no priority in the iterative computation. On the other hand, setting the queue too short may lead to frequent subpasses and as result incurs considerable overhead for the frequent queue extractions. However, the prioritized iteration is shown to improve the performance over a wide range of queue size settings as will be shown in Section \ref{sec:expr:queue}. PrIter also provides a recommended queue size setting. Anyhow, there should be an optimal queue size that results the best performance, which will be discussed in detail in Section \ref{sec:dis:queue}.